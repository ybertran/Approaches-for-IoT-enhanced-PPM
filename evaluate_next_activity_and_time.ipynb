{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from tensorflow.keras.models import load_model\n",
    "import csv\n",
    "import copy\n",
    "import numpy as np\n",
    "import distance\n",
    "from jellyfish._jellyfish import damerau_levenshtein_distance\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventlog = 'contextualised_full_context_process_event_data_iot_context_full_reworked.csv'\n",
    "csvfile = open('data/%s' % eventlog, 'r')\n",
    "datareader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "\n",
    "#helper variables\n",
    "lastcase = ''\n",
    "firstLine = True\n",
    "casestarttime = None\n",
    "lasteventtime = None\n",
    "\n",
    "#lists we need to save all the information\n",
    "lineseqs = []\n",
    "timeseqs = []\n",
    "timeseqs2 = []\n",
    "timeseqs3 = []\n",
    "\n",
    "lines = []\n",
    "caseids = []\n",
    "times = []\n",
    "times2 = []\n",
    "times3 = []\n",
    "times4 = []\n",
    "\n",
    "numlines = 0 # to count the number of lines, to know the elements per fold\n",
    "\n",
    "next(datareader, None)  # skip the headers\n",
    "for row in datareader: #the columns are \"CaseID,ActivityID,CompleteTimestamp\"\n",
    "    t = time.strptime(row[2], \"%Y-%m-%d %H:%M:%S\") #creates a datetime object from row[2]\n",
    "    if row[0]!=lastcase:  #'lastcase' is to save the last executed case for the loop\n",
    "        casestarttime = t\n",
    "        lasteventtime = t\n",
    "        lastcase = row[0]\n",
    "        if not firstLine:\n",
    "            lines.append('!')\n",
    "            lineseqs.append(lines) # the activities list\n",
    "            timeseqs.append(times) # the timeseq lists\n",
    "            timeseqs2.append(times2) \n",
    "            timeseqs3.append(times3)\n",
    "        caseids = []\n",
    "        lines = []\n",
    "        times = []  # for the timesincelastevent\n",
    "        times2 = [] # for the timesincecasestart\n",
    "        times3 = [] # saves the actual time\n",
    "        numlines+=1 # to counter the number of lines\n",
    "        \n",
    "    timesincelastevent = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(lasteventtime))\n",
    "    timesincecasestart = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(casestarttime))\n",
    "    midnight = datetime.fromtimestamp(time.mktime(t)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    timesincemidnight = datetime.fromtimestamp(time.mktime(t))-midnight\n",
    "    timediff = 86400 * timesincelastevent.days + timesincelastevent.seconds     #multiply with 60*60*24 = 86400 to go from days to seconds\n",
    "    timediff2 = 86400 * timesincecasestart.days + timesincecasestart.seconds    #the .seconds method gives the time in seconds\n",
    "    timediff3 = datetime.fromtimestamp(time.mktime(t)).weekday() #day of the week\n",
    "    caseids.append(row[0])\n",
    "    lines.append(str(row[1])) #add the activity label to the line list\n",
    "    times.append(timediff)\n",
    "    times2.append(timediff2)\n",
    "    times3.append(datetime.fromtimestamp(time.mktime(t)))\n",
    "    lasteventtime = t\n",
    "    firstLine = False\n",
    "\n",
    "# add last case\n",
    "lines.append('!')\n",
    "lineseqs.append(lines) # lists of lists contains the traces of activities per case\n",
    "timeseqs.append(times) # timesincelastevent\n",
    "timeseqs2.append(times2) # timesincecasestart\n",
    "timeseqs3.append(times3) # the actual time\n",
    "numlines+=1\n",
    "\n",
    "divisor = np.mean([item for sublist in timeseqs for item in sublist])\n",
    "print('divisor: {}'.format(divisor))\n",
    "divisor2 = np.mean([item for sublist in timeseqs2 for item in sublist])\n",
    "print('divisor2: {}'.format(divisor2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are', len(lineseqs), 'cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = max(map(lambda x: len(x),lineseqs))\n",
    "chars = map(lambda x : set(x),lineseqs)\n",
    "chars = list(set().union(*chars))\n",
    "target_chars = copy.copy(chars)\n",
    "chars.remove('!')\n",
    "# Custom sorting function to convert strings to integers for numerical sorting\n",
    "def custom_sort(item):\n",
    "    return int(item)\n",
    "\n",
    "# Sorting the list using the custom sorting function\n",
    "chars = sorted(chars, key=custom_sort)\n",
    "\n",
    "print('total chars: {}, target chars: {}'.format(len(chars), len(target_chars)))\n",
    "print('maxlen', maxlen)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "target_char_indices = dict((c, i) for i, c in enumerate(target_chars))\n",
    "target_indices_char = dict((i, c) for i, c in enumerate(target_chars))\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "predict_size = 1\n",
    "\n",
    "# load model, set this to the model generated by train.py\n",
    "model = load_model(\"output_files\\models\\model_78-1.11.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "To convert the trace activities (sentence) with associated time-related information (times and times3) into a format suitable for the LSTM\n",
    "\n",
    "sentence: The sequence of activities\n",
    "times: A list of time differences between consecutive events.\n",
    "times3: A list of timestamps for each event.\n",
    "maxlen: Maximum length of the sequence \n",
    "\n",
    "X: A 3D NumPy array representing the encoded sequence with additional features.\n",
    "\"\"\"\n",
    "\n",
    "def encode(sentence, times, times3, maxlen=maxlen):\n",
    "    num_features = len(chars)+5 # encodes an extra 5 features\n",
    "    X = np.zeros((1, maxlen, num_features), dtype=np.float32) # the encoded batch has shape [1, maxlen, num_features]\n",
    "    leftpad = maxlen-len(sentence) \n",
    "    times2 = np.cumsum(times) # returns the cumulative sum of the elements along a given axis\n",
    "    for t, char in enumerate(sentence): # Iterate over each event (char) and its index (t) in the input sequence.\n",
    "        print('char', char, 't', t)\n",
    "        midnight = times3[t].replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        timesincemidnight = times3[t]-midnight\n",
    "        multiset_abstraction = Counter(sentence[:t+1])\n",
    "        for c in chars:\n",
    "            if c==char:\n",
    "                X[0, t+leftpad, char_indices[c]] = 1\n",
    "        X[0, t+leftpad, len(chars)] = t+1 # The position of the event in the sequence (t+1).\n",
    "        X[0, t+leftpad, len(chars)+1] = times[t]/divisor # The normalized time difference (times[t]/divisor).\n",
    "        X[0, t+leftpad, len(chars)+2] = times2[t]/divisor2 # The normalized cumulative time difference (times2[t]/divisor2).\n",
    "        X[0, t+leftpad, len(chars)+3] = timesincemidnight.seconds/86400 # The normalized time since midnight (timesincemidnight.seconds/86400).\n",
    "        X[0, t+leftpad, len(chars)+4] = times3[t].weekday()/7 # The normalized day of the week (times3[t].weekday()/7).\n",
    "    return X\n",
    "\n",
    "def getSymbol(predictions):\n",
    "    maxPrediction = 0\n",
    "    symbol = ''\n",
    "    i = 0;\n",
    "    print(predictions)\n",
    "    for prediction in predictions:\n",
    "        if(prediction>=maxPrediction):\n",
    "            maxPrediction = prediction\n",
    "            symbol = target_indices_char[i]\n",
    "        i += 1\n",
    "    return symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "with open('output_files/results/next_activity_and_time_%s' % eventlog, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow([\"CaseID\", \"Prefix length\", \"Groud truth\", \"Predicted\", \"Levenshtein\", \"Damerau\", \"Jaccard\", \"Ground truth times\", \"Predicted times\", \"RMSE\", \"MAE\"])\n",
    "    for prefix_size in range(2,maxlen):\n",
    "        print('prefix size', prefix_size)\n",
    "        for line, caseid, times, times3 in zip(lineseqs, caseids, timeseqs, timeseqs3):\n",
    "            print('check')\n",
    "            times.append(0)\n",
    "            cropped_line = line[:prefix_size]\n",
    "            cropped_times = times[:prefix_size]\n",
    "            cropped_times3 = times3[:prefix_size]\n",
    "            print('cropped line', cropped_line)\n",
    "   \n",
    "            if '!' in cropped_line:\n",
    "                continue # make no prediction for this case, since this case has ended already\n",
    "            ground_truth = line[prefix_size:prefix_size+predict_size]\n",
    "            ground_truth_t = times[prefix_size:prefix_size+predict_size]\n",
    "            predicted = ''\n",
    "            predicted_t = []\n",
    "            for i in range(predict_size):\n",
    "                if len(ground_truth)<=i:\n",
    "                    continue\n",
    "                \n",
    "                enc = encode(cropped_line, cropped_times, cropped_times3)\n",
    "                print(enc.shape)\n",
    "\n",
    "                y = model.predict(enc, verbose=0)\n",
    "                print(y)\n",
    "                y_char = y[0]\n",
    "                print('ychar', y_char)\n",
    "                prediction = getSymbol(y_char)              \n",
    "                cropped_line += prediction\n",
    "            \n",
    "                if prediction == '!': # end of case was just predicted, therefore, stop predicting further into the future\n",
    "                    print('! predicted, end case')\n",
    "                    break\n",
    "                predicted += prediction\n",
    "            output = []\n",
    "            if len(ground_truth)>0:\n",
    "                output.append(caseid)\n",
    "                output.append(prefix_size)\n",
    "                output.append(str(ground_truth).encode(\"utf-8\"))\n",
    "                output.append(str(predicted).encode(\"utf-8\"))\n",
    "                output.append(1 - distance.nlevenshtein(predicted, ground_truth))\n",
    "                dls = 1 - (damerau_levenshtein_distance(str(predicted), str(ground_truth)) / max(len(predicted),len(ground_truth)))\n",
    "                if dls<0:\n",
    "                    dls=0 # we encountered problems with Damerau-Levenshtein Similarity on some linux machines where the default character encoding of the operating system caused it to be negative, this should never be the case\n",
    "                output.append(dls)\n",
    "                output.append(1 - distance.jaccard(predicted, ground_truth))\n",
    "                output.append('; '.join(str(x) for x in ground_truth_t))\n",
    "                output.append('; '.join(str(x) for x in predicted_t))\n",
    "                if len(predicted_t)>len(ground_truth_t): # if predicted more events than length of case, only use needed number of events for time evaluation\n",
    "                    predicted_t = predicted_t[:len(ground_truth_t)]\n",
    "                if len(ground_truth_t)>len(predicted_t): # if predicted less events than length of case, put 0 as placeholder prediction\n",
    "                    predicted_t.extend(range(len(ground_truth_t)-len(predicted_t)))\n",
    "                if len(ground_truth_t)>0 and len(predicted_t)>0:\n",
    "                    output.append('')\n",
    "                    output.append(metrics.mean_absolute_error([ground_truth_t[0]], [predicted_t[0]]))\n",
    "                    #output.append(metrics.median_absolute_error([ground_truth_t[0]], [predicted_t[0]]))\n",
    "                else:\n",
    "                    output.append('')\n",
    "                    output.append('')\n",
    "                    output.append('')\n",
    "                spamwriter.writerow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = ['10', '1', '14', '13', '15', '14', '15', '9', '7', '4', '14', '15', '14', '5', '15', '2', '4', '14', '15', '14', '5', '3', '13', '8', '6', '14', '15', '15', '14', '14', '15', '12', '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line[:prefix_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yannisLSTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
