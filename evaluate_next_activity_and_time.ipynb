{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from keras.models import load_model\n",
    "import csv\n",
    "import copy\n",
    "import numpy as np\n",
    "import distance\n",
    "from jellyfish._jellyfish import damerau_levenshtein_distance\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divisor: 2636.3360541044776\n",
      "divisor2: 303966.8337553305\n"
     ]
    }
   ],
   "source": [
    "eventlog = 'contextualised_full_context_process_event_data_iot_context_full_reworked.csv'\n",
    "csvfile = open('data/%s' % eventlog, 'r')\n",
    "datareader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "\n",
    "#helper variables\n",
    "lastcase = ''\n",
    "firstLine = True\n",
    "casestarttime = None\n",
    "lasteventtime = None\n",
    "\n",
    "#lists we need to save all the information\n",
    "lineseqs = []\n",
    "timeseqs = []\n",
    "timeseqs2 = []\n",
    "timeseqs3 = []\n",
    "\n",
    "lines = []\n",
    "caseids = []\n",
    "times = []\n",
    "times2 = []\n",
    "times3 = []\n",
    "times4 = []\n",
    "\n",
    "numlines = 0 # to count the number of lines, to know the elements per fold\n",
    "\n",
    "next(datareader, None)  # skip the headers\n",
    "for row in datareader: #the columns are \"CaseID,ActivityID,CompleteTimestamp\"\n",
    "    t = time.strptime(row[2], \"%Y-%m-%d %H:%M:%S\") #creates a datetime object from row[2]\n",
    "    if row[0]!=lastcase:  #'lastcase' is to save the last executed case for the loop\n",
    "        casestarttime = t\n",
    "        lasteventtime = t\n",
    "        lastcase = row[0]\n",
    "        if not firstLine:\n",
    "            lines.append('!')\n",
    "            lineseqs.append(lines) # the activities list\n",
    "            timeseqs.append(times) # the timeseq lists\n",
    "            timeseqs2.append(times2) \n",
    "            timeseqs3.append(times3)\n",
    "        caseids = []\n",
    "        lines = []\n",
    "        times = []  # for the timesincelastevent\n",
    "        times2 = [] # for the timesincecasestart\n",
    "        times3 = [] # saves the actual time\n",
    "        numlines+=1 # to counter the number of lines\n",
    "        \n",
    "    timesincelastevent = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(lasteventtime))\n",
    "    timesincecasestart = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(casestarttime))\n",
    "    midnight = datetime.fromtimestamp(time.mktime(t)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    timesincemidnight = datetime.fromtimestamp(time.mktime(t))-midnight\n",
    "    timediff = 86400 * timesincelastevent.days + timesincelastevent.seconds     #multiply with 60*60*24 = 86400 to go from days to seconds\n",
    "    timediff2 = 86400 * timesincecasestart.days + timesincecasestart.seconds    #the .seconds method gives the time in seconds\n",
    "    timediff3 = datetime.fromtimestamp(time.mktime(t)).weekday() #day of the week\n",
    "    caseids.append(row[0])\n",
    "    lines.append(str(row[1])) #add the activity label to the line list\n",
    "    times.append(timediff)\n",
    "    times2.append(timediff2)\n",
    "    times3.append(datetime.fromtimestamp(time.mktime(t)))\n",
    "    lasteventtime = t\n",
    "    firstLine = False\n",
    "\n",
    "# add last case\n",
    "lines.append('!')\n",
    "lineseqs.append(lines) # lists of lists contains the traces of activities per case\n",
    "timeseqs.append(times) # timesincelastevent\n",
    "timeseqs2.append(times2) # timesincecasestart\n",
    "timeseqs3.append(times3) # the actual time\n",
    "numlines+=1\n",
    "\n",
    "divisor = np.mean([item for sublist in timeseqs for item in sublist])\n",
    "print('divisor: {}'.format(divisor))\n",
    "divisor2 = np.mean([item for sublist in timeseqs2 for item in sublist])\n",
    "print('divisor2: {}'.format(divisor2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 157 cases\n"
     ]
    }
   ],
   "source": [
    "print('There are', len(lineseqs), 'cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 51, target chars: 52\n",
      "maxlen 635\n",
      "{0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '10', 11: '11', 12: '12', 13: '13', 14: '14', 15: '15', 16: '16', 17: '17', 18: '18', 19: '19', 20: '20', 21: '21', 22: '22', 23: '23', 24: '24', 25: '25', 26: '26', 27: '27', 28: '28', 29: '29', 30: '30', 31: '31', 32: '32', 33: '33', 34: '34', 35: '35', 36: '36', 37: '37', 38: '38', 39: '39', 40: '40', 41: '41', 42: '42', 43: '43', 44: '44', 45: '45', 46: '46', 47: '47', 48: '48', 49: '49', 50: '50'}\n"
     ]
    }
   ],
   "source": [
    "maxlen = max(map(lambda x: len(x),lineseqs))\n",
    "chars = map(lambda x : set(x),lineseqs)\n",
    "chars = list(set().union(*chars))\n",
    "target_chars = copy.copy(chars)\n",
    "chars.remove('!')\n",
    "# Custom sorting function to convert strings to integers for numerical sorting\n",
    "def custom_sort(item):\n",
    "    return int(item)\n",
    "\n",
    "# Sorting the list using the custom sorting function\n",
    "chars = sorted(chars, key=custom_sort)\n",
    "\n",
    "print('total chars: {}, target chars: {}'.format(len(chars), len(target_chars)))\n",
    "print('maxlen', maxlen)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "target_char_indices = dict((c, i) for i, c in enumerate(target_chars))\n",
    "target_indices_char = dict((i, c) for i, c in enumerate(target_chars))\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'output_files\\models\\model_78-1.11.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m predict_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# load model, set this to the model generated by train.py\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_files\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmodel_78-1.11.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\IOTPPM\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    177\u001b[0m         filepath,\n\u001b[0;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\IOTPPM\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:116\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    114\u001b[0m opened_new_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opened_new_file:\n\u001b[1;32m--> 116\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     f \u001b[38;5;241m=\u001b[39m filepath\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\IOTPPM\\Lib\\site-packages\\h5py\\_hl\\files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\IOTPPM\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'output_files\\models\\model_78-1.11.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# set parameters\n",
    "predict_size = 1\n",
    "\n",
    "# load model, set this to the model generated by train.py\n",
    "model = load_model(\"output_files\\models\\model_78-1.11.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "To convert the trace activities (sentence) with associated time-related information (times and times3) into a format suitable for the LSTM\n",
    "\n",
    "sentence: The sequence of activities\n",
    "times: A list of time differences between consecutive events.\n",
    "times3: A list of timestamps for each event.\n",
    "maxlen: Maximum length of the sequence \n",
    "\n",
    "X: A 3D NumPy array representing the encoded sequence with additional features.\n",
    "\"\"\"\n",
    "\n",
    "def encode(sentence, times, times3, maxlen=maxlen):\n",
    "    num_features = len(chars)+5 # encodes an extra 5 features\n",
    "    X = np.zeros((1, maxlen, num_features), dtype=np.float32) # the encoded batch has shape [1, maxlen, num_features]\n",
    "    leftpad = maxlen-len(sentence) \n",
    "    times2 = np.cumsum(times) # returns the cumulative sum of the elements along a given axis\n",
    "    for t, char in enumerate(sentence): # Iterate over each event (char) and its index (t) in the input sequence.\n",
    "        print('char', char, 't', t)\n",
    "        midnight = times3[t].replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        timesincemidnight = times3[t]-midnight\n",
    "        multiset_abstraction = Counter(sentence[:t+1])\n",
    "        for c in chars:\n",
    "            if c==char:\n",
    "                X[0, t+leftpad, char_indices[c]] = 1\n",
    "        X[0, t+leftpad, len(chars)] = t+1 # The position of the event in the sequence (t+1).\n",
    "        X[0, t+leftpad, len(chars)+1] = times[t]/divisor # The normalized time difference (times[t]/divisor).\n",
    "        X[0, t+leftpad, len(chars)+2] = times2[t]/divisor2 # The normalized cumulative time difference (times2[t]/divisor2).\n",
    "        X[0, t+leftpad, len(chars)+3] = timesincemidnight.seconds/86400 # The normalized time since midnight (timesincemidnight.seconds/86400).\n",
    "        X[0, t+leftpad, len(chars)+4] = times3[t].weekday()/7 # The normalized day of the week (times3[t].weekday()/7).\n",
    "    return X\n",
    "\n",
    "def getSymbol(predictions):\n",
    "    maxPrediction = 0\n",
    "    symbol = ''\n",
    "    i = 0;\n",
    "    print(predictions)\n",
    "    for prediction in predictions:\n",
    "        if(prediction>=maxPrediction):\n",
    "            maxPrediction = prediction\n",
    "            symbol = target_indices_char[i]\n",
    "        i += 1\n",
    "    return symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output_files/results/next_activity_and_time_contextualised_full_context_process_event_data_iot_context_full_reworked.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# make predictions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_files/results/next_activity_and_time_\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meventlog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[0;32m      3\u001b[0m     spamwriter \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(csvfile, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m, quoting\u001b[38;5;241m=\u001b[39mcsv\u001b[38;5;241m.\u001b[39mQUOTE_MINIMAL)\n\u001b[0;32m      4\u001b[0m     spamwriter\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCaseID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrefix length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroud truth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLevenshtein\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDamerau\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJaccard\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGround truth times\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted times\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\IOTPPM\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output_files/results/next_activity_and_time_contextualised_full_context_process_event_data_iot_context_full_reworked.csv'"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "with open('output_files/results/next_activity_and_time_%s' % eventlog, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow([\"CaseID\", \"Prefix length\", \"Groud truth\", \"Predicted\", \"Levenshtein\", \"Damerau\", \"Jaccard\", \"Ground truth times\", \"Predicted times\", \"RMSE\", \"MAE\"])\n",
    "    for prefix_size in range(2,maxlen):\n",
    "        print('prefix size', prefix_size)\n",
    "        for line, caseid, times, times3 in zip(lineseqs, caseids, timeseqs, timeseqs3):\n",
    "            print('check')\n",
    "            times.append(0)\n",
    "            cropped_line = line[:prefix_size]\n",
    "            cropped_times = times[:prefix_size]\n",
    "            cropped_times3 = times3[:prefix_size]\n",
    "            print('cropped line', cropped_line)\n",
    "   \n",
    "            if '!' in cropped_line:\n",
    "                continue # make no prediction for this case, since this case has ended already\n",
    "            ground_truth = line[prefix_size:prefix_size+predict_size]\n",
    "            ground_truth_t = times[prefix_size:prefix_size+predict_size]\n",
    "            predicted = ''\n",
    "            predicted_t = []\n",
    "            for i in range(predict_size):\n",
    "                if len(ground_truth)<=i:\n",
    "                    continue\n",
    "                \n",
    "                enc = encode(cropped_line, cropped_times, cropped_times3)\n",
    "                print(enc.shape)\n",
    "\n",
    "                y = model.predict(enc, verbose=0)\n",
    "                print(y)\n",
    "                y_char = y[0]\n",
    "                print('ychar', y_char)\n",
    "                prediction = getSymbol(y_char)              \n",
    "                cropped_line += prediction\n",
    "            \n",
    "                if prediction == '!': # end of case was just predicted, therefore, stop predicting further into the future\n",
    "                    print('! predicted, end case')\n",
    "                    break\n",
    "                predicted += prediction\n",
    "            output = []\n",
    "            if len(ground_truth)>0:\n",
    "                output.append(caseid)\n",
    "                output.append(prefix_size)\n",
    "                output.append(str(ground_truth).encode(\"utf-8\"))\n",
    "                output.append(str(predicted).encode(\"utf-8\"))\n",
    "                output.append(1 - distance.nlevenshtein(predicted, ground_truth))\n",
    "                dls = 1 - (damerau_levenshtein_distance(str(predicted), str(ground_truth)) / max(len(predicted),len(ground_truth)))\n",
    "                if dls<0:\n",
    "                    dls=0 # we encountered problems with Damerau-Levenshtein Similarity on some linux machines where the default character encoding of the operating system caused it to be negative, this should never be the case\n",
    "                output.append(dls)\n",
    "                output.append(1 - distance.jaccard(predicted, ground_truth))\n",
    "                output.append('; '.join(str(x) for x in ground_truth_t))\n",
    "                output.append('; '.join(str(x) for x in predicted_t))\n",
    "                if len(predicted_t)>len(ground_truth_t): # if predicted more events than length of case, only use needed number of events for time evaluation\n",
    "                    predicted_t = predicted_t[:len(ground_truth_t)]\n",
    "                if len(ground_truth_t)>len(predicted_t): # if predicted less events than length of case, put 0 as placeholder prediction\n",
    "                    predicted_t.extend(range(len(ground_truth_t)-len(predicted_t)))\n",
    "                if len(ground_truth_t)>0 and len(predicted_t)>0:\n",
    "                    output.append('')\n",
    "                    output.append(metrics.mean_absolute_error([ground_truth_t[0]], [predicted_t[0]]))\n",
    "                    #output.append(metrics.median_absolute_error([ground_truth_t[0]], [predicted_t[0]]))\n",
    "                else:\n",
    "                    output.append('')\n",
    "                    output.append('')\n",
    "                    output.append('')\n",
    "                spamwriter.writerow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = ['10', '1', '14', '13', '15', '14', '15', '9', '7', '4', '14', '15', '14', '5', '15', '2', '4', '14', '15', '14', '5', '3', '13', '8', '6', '14', '15', '15', '14', '14', '15', '12', '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10', '1']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line[:prefix_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
