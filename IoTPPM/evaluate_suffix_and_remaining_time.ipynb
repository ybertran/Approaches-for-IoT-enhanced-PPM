{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this script takes as input the LSTM or RNN weights found by train.py\n",
    "change the path in line 178 of this script to point to the h5 file\n",
    "with LSTM or RNN weights generated by train.py\n",
    "'''\n",
    "\n",
    "from __future__ import division\n",
    "from keras.models import load_model\n",
    "import csv\n",
    "import copy\n",
    "import numpy as np\n",
    "import distance\n",
    "from jellyfish._jellyfish import damerau_levenshtein_distance\n",
    "import unicodecsv\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divisor: 8329.618428334255\n",
      "divisor2: 257467.7155506364\n",
      "divisor3: 288305.9640935422\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "#define the maximum length of events\n",
    "def find_max_list(lst):\n",
    "    list_len = [len(i) for i in lst]\n",
    "    return max(list_len)\n",
    "\n",
    "\n",
    "# define helper functions\n",
    "def encode(sentence, times, times3, maxlen, act_indices, activities):\n",
    "    print(sentence, times, times3)\n",
    "    num_features = len(activities)+5\n",
    "    X = np.zeros((1, maxlen, num_features), dtype=np.float32)\n",
    "    leftpad = maxlen-len(sentence)\n",
    "    times2 = np.cumsum(times)\n",
    "    for t, char in enumerate(sentence):\n",
    "        midnight = times3[t].replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        timesincemidnight = times3[t]-midnight\n",
    "        multiset_abstraction = Counter(sentence[:t+1])\n",
    "        for c in activities:\n",
    "            if c==char:\n",
    "                X[0, t+leftpad, act_indices[c]] = 1\n",
    "        X[0, t+leftpad, len(activities)] = t+1\n",
    "        X[0, t+leftpad, len(activities)+1] = times[t]/divisor\n",
    "        X[0, t+leftpad, len(activities)+2] = times2[t]/divisor2\n",
    "        X[0, t+leftpad, len(activities)+3] = timesincemidnight.seconds/86400\n",
    "        X[0, t+leftpad, len(activities)+4] = times3[t].weekday()/7\n",
    "    return X\n",
    "\n",
    "def getSymbol(predictions, target_indices_activities):\n",
    "    maxPrediction = 0\n",
    "    symbol = ''\n",
    "    i = 0;\n",
    "    for prediction in predictions:\n",
    "        if(prediction>=maxPrediction):\n",
    "            maxPrediction = prediction\n",
    "            symbol = target_indices_activities[i]\n",
    "        i += 1\n",
    "    return symbol\n",
    "\n",
    "eventlog = 'event_data_alexander_rounded.csv'\n",
    "csvfile = open('data/%s' % eventlog, 'r')\n",
    "datareader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "\n",
    "#helper variables\n",
    "lastcase = ''\n",
    "firstLine = True\n",
    "lineseq = []\n",
    "timeseqs = []\n",
    "timeseqs2 = []\n",
    "timeseqs3 = []\n",
    "timeseqs4 = []\n",
    "caseidseqs = []\n",
    "lines = []\n",
    "caseids = []\n",
    "times = []\n",
    "times2 = []\n",
    "times3 = []\n",
    "times4 = []\n",
    "numlines = 0\n",
    "casestarttime = None\n",
    "lasteventtime = None\n",
    "\n",
    "next(datareader, None)  # skip the headers\n",
    "for row in datareader: #the columns are \"CaseID,ActivityID,CompleteTimestamp\"\n",
    "    t = time.strptime(row[2], \"%Y-%m-%d %H:%M:%S\") #creates a datetime object from row[2]\n",
    "    if row[0]!=lastcase:  #'lastcase' is to save the last executed case for the loop\n",
    "        casestarttime = t\n",
    "        lasteventtime = t\n",
    "        lastcase = row[0]\n",
    "        if not firstLine:\n",
    "            lineseq.append(lines)\n",
    "            timeseqs.append(times)\n",
    "            timeseqs2.append(times2)\n",
    "            timeseqs3.append(times3)\n",
    "            timeseqs4.append(times4)\n",
    "        lines = []\n",
    "        times = []\n",
    "        times2 = []\n",
    "        times3 = []\n",
    "        times4 = []\n",
    "        numlines+=1\n",
    "    timesincelastevent = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(lasteventtime))\n",
    "    timesincecasestart = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(casestarttime))\n",
    "    midnight = datetime.fromtimestamp(time.mktime(t)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    timesincemidnight = datetime.fromtimestamp(time.mktime(t))-midnight\n",
    "    timediff = 86400 * timesincelastevent.days + timesincelastevent.seconds     #multiply with 60*60*24 = 86400 to go from days to seconds\n",
    "    timediff2 = 86400 * timesincecasestart.days + timesincecasestart.seconds    #the .seconds method gives the time in seconds\n",
    "    timediff4 = datetime.fromtimestamp(time.mktime(t)).weekday() #day of the week\n",
    "    lines.append(str(row[1])) #add the activity label to the line list\n",
    "    caseids.append(row[0])\n",
    "    times.append(timediff)\n",
    "    times2.append(timediff2)\n",
    "    times3.append(datetime.fromtimestamp(time.mktime(t)))\n",
    "    times4.append(timediff4)\n",
    "    lasteventtime = t\n",
    "    firstLine = False\n",
    "\n",
    "# add last case\n",
    "caseidseqs.append(caseids)\n",
    "lineseq.append(lines)\n",
    "timeseqs.append(times)\n",
    "timeseqs2.append(times2)\n",
    "timeseqs3.append(times3)\n",
    "timeseqs4.append(times4)\n",
    "numlines+=1\n",
    "\n",
    "divisor = np.mean([item for sublist in timeseqs for item in sublist])\n",
    "print('divisor: {}'.format(divisor))\n",
    "divisor2 = np.mean([item for sublist in timeseqs2 for item in sublist])\n",
    "print('divisor2: {}'.format(divisor2))\n",
    "divisor3 = np.mean(list(map(lambda x: np.mean(list(map(lambda y: x[len(x)-1]-y, x))), timeseqs2)))\n",
    "print('divisor3: {}'.format(divisor3))\n",
    "#########################################################################################################\n",
    "# separate data into 3 parts\n",
    "elems_per_fold = int(round(numlines/3))\n",
    "fold1 = lineseq[:elems_per_fold]\n",
    "fold1_t = timeseqs[:elems_per_fold]\n",
    "fold1_t2 = timeseqs2[:elems_per_fold]\n",
    "fold1_t3 = timeseqs3[:elems_per_fold]\n",
    "fold1_t4 = timeseqs4[:elems_per_fold]\n",
    "import csv\n",
    "with open('code/output_files/folds/fold1.csv', 'w', newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row, timeseq in zip(fold1, fold1_t):\n",
    "        datawriter.writerow([f\"{s}#{t}\" for s, t in zip(row, timeseq)])\n",
    "\n",
    "\n",
    "fold2 = lineseq[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t = timeseqs[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t2 = timeseqs2[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t3 = timeseqs3[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t4 = timeseqs4[elems_per_fold:2*elems_per_fold]\n",
    "with open('code/output_files/folds/fold2.csv', 'w', newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row, timeseq in zip(fold2, fold2_t):\n",
    "        datawriter.writerow([f\"{s}#{t}\" for s, t in zip(row, timeseq)])\n",
    "\n",
    "fold3 = lineseq[2*elems_per_fold:]\n",
    "fold3_c = caseids[2*elems_per_fold:]\n",
    "fold3_t = timeseqs[2*elems_per_fold:]\n",
    "fold3_t2 = timeseqs2[2*elems_per_fold:]\n",
    "fold3_t3 = timeseqs3[2*elems_per_fold:]\n",
    "fold3_t4 = timeseqs4[2*elems_per_fold:]\n",
    "with open('code/output_files/folds/fold3.csv','w', newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row, timeseq in zip(fold3, fold3_t):\n",
    "        datawriter.writerow([f\"{s}#{t}\" for s, t in zip(row, timeseq)])\n",
    "\n",
    "lines = fold3\n",
    "caseids = fold3_c\n",
    "lines_t = fold3_t\n",
    "lines_t2 = fold3_t2\n",
    "lines_t3 = fold3_t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lineseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(caseids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timeseqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(fold3[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "print(len(fold3_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are: 15 different activities\n",
      "total activities: 15, target activities: 15\n",
      "{0: '13', 1: '8', 2: '15', 3: '9', 4: '14', 5: '2', 6: '10', 7: '5', 8: '12', 9: '4', 10: '11', 11: '1', 12: '6', 13: '3', 14: '7'}\n",
      "2\n",
      "['1', '10'] [0, 192] [datetime.datetime(2021, 10, 5, 6, 18, 58), datetime.datetime(2021, 10, 5, 6, 22, 10)]\n",
      "['1', '10', '1', '0'] [0, 192, 0.13749832] [datetime.datetime(2021, 10, 5, 6, 18, 58), datetime.datetime(2021, 10, 5, 6, 22, 10), datetime.datetime(2021, 10, 5, 17, 22, 51, 585463)]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m total_predicted_time \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     46\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(predict_size):\n\u001b[1;32m---> 47\u001b[0m     enc \u001b[39m=\u001b[39m encode(cropped_line, cropped_times, cropped_times3, maxlen, act_indices, activities)\n\u001b[0;32m     48\u001b[0m     y \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(enc, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m# make predictions\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[39m# split predictions into seperate activity and time predictions\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[32], line 18\u001b[0m, in \u001b[0;36mencode\u001b[1;34m(sentence, times, times3, maxlen, act_indices, activities)\u001b[0m\n\u001b[0;32m     16\u001b[0m times2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcumsum(times)\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m t, char \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sentence):\n\u001b[1;32m---> 18\u001b[0m     midnight \u001b[39m=\u001b[39m times3[t]\u001b[39m.\u001b[39mreplace(hour\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, minute\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, second\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, microsecond\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     19\u001b[0m     timesincemidnight \u001b[39m=\u001b[39m times3[t]\u001b[39m-\u001b[39mmidnight\n\u001b[0;32m     20\u001b[0m     multiset_abstraction \u001b[39m=\u001b[39m Counter(sentence[:t\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "maxlen = find_max_list(fold1+fold2) #find maximum line size\n",
    "# set parameters\n",
    "predict_size = maxlen\n",
    "activities = set([item for sublist in fold1+fold2 for item in sublist])\n",
    "target_activities = copy.copy(activities)\n",
    "print('there are:', len(activities), 'different activities')\n",
    "\n",
    "print('total activities: {}, target activities: {}'.format(len(activities), len(target_activities)))\n",
    "act_indices = dict((c, i) for i, c in enumerate(activities))\n",
    "indices_act = dict((i, c) for i, c in enumerate(activities))\n",
    "target_activities_indices = dict((c, i) for i, c in enumerate(target_activities))\n",
    "target_indices_activities = dict((i, c) for i, c in enumerate(target_activities))\n",
    "print(indices_act)\n",
    "\n",
    "# load model, set this to the model generated by train.py\n",
    "model = load_model('output_files/models/model_63-1.38.h5')\n",
    "\n",
    "one_ahead_gt = []\n",
    "one_ahead_pred = []\n",
    "\n",
    "two_ahead_gt = []\n",
    "two_ahead_pred = []\n",
    "\n",
    "three_ahead_gt = []\n",
    "three_ahead_pred = []\n",
    "\n",
    "# make predictions\n",
    "with open('output_files/results/suffix_and_remaining_time_%s' % eventlog, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow([\"CaseID\", \"Prefix length\", \"Groud truth\", \"Predicted\", \"Levenshtein\", \"Damerau\", \"Jaccard\", \"Ground truth times\", \"Predicted times\", \"RMSE\", \"MAE\"])\n",
    "    for prefix_size in range(2,maxlen):\n",
    "        print(prefix_size)\n",
    "        for line, caseid, times, times2, times3 in zip(lines, caseids, lines_t, lines_t2, lines_t3):\n",
    "            times.append(0)\n",
    "            cropped_line = line[:prefix_size]\n",
    "            cropped_times = times[:prefix_size]\n",
    "            cropped_times3 = times3[:prefix_size]\n",
    "            if len(times2)<prefix_size:\n",
    "                continue # make no prediction for this case, since this case has ended already\n",
    "            ground_truth = ''.join(line[prefix_size:prefix_size+predict_size])\n",
    "            ground_truth_t = times2[prefix_size-1]\n",
    "            case_end_time = times2[len(times2)-1]\n",
    "            ground_truth_t = case_end_time-ground_truth_t\n",
    "            predicted = ''\n",
    "            total_predicted_time = 0\n",
    "            for i in range(predict_size):\n",
    "                enc = encode(cropped_line, cropped_times, cropped_times3, maxlen, act_indices, activities)\n",
    "                y = model.predict(enc, verbose=0) # make predictions\n",
    "                # split predictions into seperate activity and time predictions\n",
    "                y_char = y[0][0] \n",
    "                y_t = y[1][0][0]\n",
    "                prediction = getSymbol(y_char, target_indices_activities) # undo one-hot encoding           \n",
    "                cropped_line += prediction\n",
    "                if y_t<0:\n",
    "                    y_t=0\n",
    "                cropped_times.append(y_t)\n",
    "                if prediction == '!': # end of case was just predicted, therefore, stop predicting further into the future\n",
    "                    one_ahead_pred.append(total_predicted_time)\n",
    "                    one_ahead_gt.append(ground_truth_t)\n",
    "                    print('! predicted, end case')\n",
    "                    break\n",
    "                y_t = y_t * divisor3\n",
    "                cropped_times3.append(cropped_times3[-1] + timedelta(seconds=y_t))\n",
    "                total_predicted_time = total_predicted_time + y_t\n",
    "                predicted += prediction\n",
    "            output = []\n",
    "            if len(ground_truth)>0:\n",
    "                output.append(caseid)\n",
    "                output.append(prefix_size)\n",
    "                output.append(str(ground_truth).encode(\"utf-8\"))\n",
    "                output.append(StopIteration(predicted))\n",
    "                output.append(1 - distance.nlevenshtein(predicted, ground_truth))\n",
    "                dls = 1 - (damerau_levenshtein_distance(str(predicted), str(ground_truth)) / max(len(predicted),len(ground_truth)))\n",
    "                if dls<0:\n",
    "                    dls=0 # we encountered problems with Damerau-Levenshtein Similarity on some linux machines where the default character encoding of the operating system caused it to be negative, this should never be the case\n",
    "                output.append(dls)\n",
    "                output.append(1 - distance.jaccard(predicted, ground_truth))\n",
    "                output.append(ground_truth_t)\n",
    "                output.append(total_predicted_time)\n",
    "                output.append('')\n",
    "                output.append(metrics.mean_absolute_error([ground_truth_t], [total_predicted_time]))\n",
    "                #output.append(metrics.median_absolute_error([ground_truth_t], [total_predicted_time]))\n",
    "                spamwriter.writerow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_line, cropped_times, cropped_times3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IOTPPM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
