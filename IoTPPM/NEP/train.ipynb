{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, Dense, Input, BatchNormalization\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from collections import Counter\n",
    "import unicodecsv\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "from math import log\n",
    "from sklearn import preprocessing\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "#read in original data\n",
    "df_orig = pd.read_csv('data/event_data_alexander.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the data (10842, 3)\n"
     ]
    }
   ],
   "source": [
    "#rename the column names\n",
    "df_orig.rename(columns={'concept:name': 'ActivityID', 'batch_id': 'CaseID', 'timestamp': 'CompleteTimestamp'}, inplace=True)\n",
    "\n",
    "#only keep the relevant columns\n",
    "df_orig = df_orig[['CaseID','ActivityID','CompleteTimestamp']]\n",
    "\n",
    "#labelencode the activity labels\n",
    "le_act = preprocessing.LabelEncoder()\n",
    "df_orig['ActivityID'] = le_act.fit_transform(df_orig['ActivityID'])+1\n",
    "\n",
    "#labelencode the case IDs\n",
    "le_case = preprocessing.LabelEncoder()\n",
    "df_orig['CaseID'] = le_case.fit_transform(df_orig['CaseID'])+1\n",
    "\n",
    "#remove the milliseconds\n",
    "df_orig['CompleteTimestamp'] = df_orig['CompleteTimestamp'].str[:-4]\n",
    "\n",
    "#take a sample of 5 cases\n",
    "#df_orig = df_orig[df_orig['CaseID'].isin([1,2,3,4,5])]\n",
    "df_orig['CaseID'].nunique()\n",
    "\n",
    "#sort values by CaseID\n",
    "df_orig = df_orig.sort_values(['CaseID','CompleteTimestamp'])\n",
    "\n",
    "\n",
    "#save and load again\n",
    "df_orig.to_csv('data/event_data_yannis.csv', index=False)\n",
    "df_new = pd.read_csv('data/event_data_alexander_rounded.csv')\n",
    "print('the shape of the data',df_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1Pass_Prewet', 'Adjustment Charging', 'Agitation',\n",
       "       'Agitator start', 'Agitator stop', 'Bottling', 'Charging',\n",
       "       'Circulation', 'Circulation Prewet', 'Filters',\n",
       "       'Line Loss Collection', 'Postwash', 'Pump adjustment',\n",
       "       'Pump start', 'Pump stop'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_act.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n"
     ]
    }
   ],
   "source": [
    "print(df_new['CaseID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CaseID</th>\n",
       "      <th>ActivityID</th>\n",
       "      <th>CompleteTimestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-10-14 13:00:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-14 13:16:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-10-14 13:38:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-14 16:43:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-10-14 17:59:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CaseID  ActivityID    CompleteTimestamp\n",
       "0       1          10  2020-10-14 13:00:57\n",
       "1       1           1  2020-10-14 13:16:00\n",
       "2       1          10  2020-10-14 13:38:51\n",
       "3       1           1  2020-10-14 16:43:32\n",
       "4       1           9  2020-10-14 17:59:29"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_orig['ActivityID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divisor: 8329.618428334255\n",
      "divisor2: 257467.7155506364\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "#define the maximum length of events\n",
    "def find_max_list(lst):\n",
    "    list_len = [len(i) for i in lst]\n",
    "    return max(list_len)\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "#this basically creates lists of lists with all the relevant information\n",
    "########################################################################################\n",
    "\n",
    "eventlog = 'event_data_alexander_rounded.csv'\n",
    "csvfile = open('data/%s' % eventlog, 'r')\n",
    "datareader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "\n",
    "#helper variables\n",
    "lastcase = ''\n",
    "firstLine = True\n",
    "lineseq = []\n",
    "timeseqs = []\n",
    "timeseqs2 = []\n",
    "timeseqs3 = []\n",
    "timeseqs4 = []\n",
    "lines = []\n",
    "times = []\n",
    "times2 = []\n",
    "times3 = []\n",
    "times4 = []\n",
    "numlines = 0\n",
    "casestarttime = None\n",
    "lasteventtime = None\n",
    "\n",
    "next(datareader, None)  # skip the headers\n",
    "for row in datareader: #the columns are \"CaseID,ActivityID,CompleteTimestamp\"\n",
    "    t = time.strptime(row[2], \"%Y-%m-%d %H:%M:%S\") #creates a datetime object from row[2]\n",
    "    if row[0]!=lastcase:  #'lastcase' is to save the last executed case for the loop\n",
    "        casestarttime = t\n",
    "        lasteventtime = t\n",
    "        lastcase = row[0]\n",
    "        if not firstLine:\n",
    "            lineseq.append(lines)\n",
    "            timeseqs.append(times)\n",
    "            timeseqs2.append(times2)\n",
    "            timeseqs3.append(times3)\n",
    "            timeseqs4.append(times4)\n",
    "        lines = []\n",
    "        times = []\n",
    "        times2 = []\n",
    "        times3 = []\n",
    "        times4 = []\n",
    "        numlines+=1\n",
    "    timesincelastevent = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(lasteventtime))\n",
    "    timesincecasestart = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(casestarttime))\n",
    "    midnight = datetime.fromtimestamp(time.mktime(t)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    timesincemidnight = datetime.fromtimestamp(time.mktime(t))-midnight\n",
    "    timediff = 86400 * timesincelastevent.days + timesincelastevent.seconds     #multiply with 60*60*24 = 86400 to go from days to seconds\n",
    "    timediff2 = 86400 * timesincecasestart.days + timesincecasestart.seconds    #the .seconds method gives the time in seconds\n",
    "    timediff3 = timesincemidnight.seconds #this leaves only time event occured after midnight\n",
    "    timediff4 = datetime.fromtimestamp(time.mktime(t)).weekday() #day of the week\n",
    "    lines.append(str(row[1])) #add the activity label to the line list\n",
    "    times.append(timediff)\n",
    "    times2.append(timediff2)\n",
    "    times3.append(timediff3)\n",
    "    times4.append(timediff4)\n",
    "    lasteventtime = t\n",
    "    firstLine = False\n",
    "\n",
    "# add last case\n",
    "lineseq.append(lines)\n",
    "timeseqs.append(times)\n",
    "timeseqs2.append(times2)\n",
    "timeseqs3.append(times3)\n",
    "timeseqs4.append(times4)\n",
    "numlines+=1\n",
    "\n",
    "divisor = np.mean([item for sublist in timeseqs for item in sublist]) #average time between events\n",
    "print('divisor: {}'.format(divisor))\n",
    "divisor2 = np.mean([item for sublist in timeseqs2 for item in sublist]) #average time between current and first events\n",
    "print('divisor2: {}'.format(divisor2))\n",
    "\n",
    "#########################################################################################################\n",
    "# separate data into 3 parts\n",
    "elems_per_fold = int(round(numlines/3))\n",
    "fold1 = lineseq[:elems_per_fold]\n",
    "fold1_t = timeseqs[:elems_per_fold]\n",
    "fold1_t2 = timeseqs2[:elems_per_fold]\n",
    "fold1_t3 = timeseqs3[:elems_per_fold]\n",
    "fold1_t4 = timeseqs4[:elems_per_fold]\n",
    "import csv\n",
    "with open('code/output_files/folds/fold1.csv', 'w', newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row, timeseq in zip(fold1, fold1_t):\n",
    "        datawriter.writerow([f\"{s}#{t}\" for s, t in zip(row, timeseq)])\n",
    "\n",
    "\n",
    "fold2 = lineseq[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t = timeseqs[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t2 = timeseqs2[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t3 = timeseqs3[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t4 = timeseqs4[elems_per_fold:2*elems_per_fold]\n",
    "with open('code/output_files/folds/fold2.csv', 'w', newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row, timeseq in zip(fold2, fold2_t):\n",
    "        datawriter.writerow([f\"{s}#{t}\" for s, t in zip(row, timeseq)])\n",
    "\n",
    "fold3 = lineseq[2*elems_per_fold:]\n",
    "fold3_t = timeseqs[2*elems_per_fold:]\n",
    "fold3_t2 = timeseqs2[2*elems_per_fold:]\n",
    "fold3_t3 = timeseqs3[2*elems_per_fold:]\n",
    "fold3_t4 = timeseqs4[2*elems_per_fold:]\n",
    "with open('code/output_files/folds/fold3.csv','w', newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row, timeseq in zip(fold3, fold3_t):\n",
    "        datawriter.writerow([f\"{s}#{t}\" for s, t in zip(row, timeseq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = fold1 + fold2\n",
    "lines_t = fold1_t + fold2_t\n",
    "lines_t2 = fold1_t2 + fold2_t2\n",
    "lines_t3 = fold1_t3 + fold2_t3\n",
    "lines_t4 = fold1_t4 + fold2_t4\n",
    "\n",
    "step = 1\n",
    "sentences = []\n",
    "softness = 0\n",
    "next_chars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are now: 6509 prefix sequences\n",
      "there are: 15 different activities\n"
     ]
    }
   ],
   "source": [
    "#helper variables\n",
    "step = 1\n",
    "sentences = []\n",
    "softness = 0\n",
    "next_chars = []\n",
    "sentences_t = []\n",
    "sentences_t2 = []\n",
    "sentences_t3 = []\n",
    "sentences_t4 = []\n",
    "next_chars_t = []\n",
    "next_chars_t2 = []\n",
    "next_chars_t3 = []\n",
    "next_chars_t4 = []\n",
    "maxlen = find_max_list(lines) #find maximum line size\n",
    "\n",
    "for line, line_t, line_t2, line_t3, line_t4 in zip(lines, lines_t, lines_t2, lines_t3, lines_t4):\n",
    "    for i in range(0, len(line), step):\n",
    "        if i==0:\n",
    "            continue\n",
    "        #we take all the prefix traces of the traces\n",
    "        #we add iteratively, first symbol of the line, then two first, three...\n",
    "        sentences.append(line[0:i])\n",
    "        sentences_t.append(line_t[0:i])\n",
    "        sentences_t2.append(line_t2[0:i])\n",
    "        sentences_t3.append(line_t3[0:i])\n",
    "        sentences_t4.append(line_t4[0:i])\n",
    "        next_chars.append(line[i])\n",
    "        if i==len(line)-1: # special case to deal time of end character\n",
    "            next_chars_t.append(0)\n",
    "            next_chars_t2.append(0)\n",
    "            next_chars_t3.append(0)\n",
    "            next_chars_t4.append(0)\n",
    "        else:\n",
    "            next_chars_t.append(line_t[i])\n",
    "            next_chars_t2.append(line_t2[i])\n",
    "            next_chars_t3.append(line_t3[i])\n",
    "            next_chars_t4.append(line_t4[i])\n",
    "activities = set([item for sublist in lineseq for item in sublist])\n",
    "target_activities = copy.copy(activities)\n",
    "print('there are now:', len(sentences), 'prefix sequences')\n",
    "print('there are:', len(activities), 'different activities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total activities: 15, target activities: 15\n",
      "{0: '13', 1: '3', 2: '7', 3: '4', 4: '5', 5: '12', 6: '10', 7: '14', 8: '6', 9: '11', 10: '1', 11: '15', 12: '9', 13: '8', 14: '2'}\n",
      "Vectorization...\n",
      "num features: 20\n"
     ]
    }
   ],
   "source": [
    "print('total activities: {}, target activities: {}'.format(len(activities), len(target_activities)))\n",
    "act_indices = dict((c, i) for i, c in enumerate(activities))\n",
    "indices_act = dict((i, c) for i, c in enumerate(activities))\n",
    "target_activities_indices = dict((c, i) for i, c in enumerate(target_activities))\n",
    "target_indices_activities = dict((i, c) for i, c in enumerate(target_activities))\n",
    "print(indices_act)\n",
    "\n",
    "print('Vectorization...')\n",
    "num_features = len(activities)+5\n",
    "print('num features: {}'.format(num_features))\n",
    "X = np.zeros((len(sentences), maxlen, num_features), dtype=np.float32)\n",
    "y_a = np.zeros((len(sentences), len(target_activities)), dtype=np.float32)\n",
    "y_t = np.zeros((len(sentences)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    leftpad = maxlen-len(sentence)\n",
    "    next_t = next_chars_t[i]\n",
    "    sentence_t = sentences_t[i]\n",
    "    sentence_t2 = sentences_t2[i]\n",
    "    sentence_t3 = sentences_t3[i]\n",
    "    sentence_t4 = sentences_t4[i]\n",
    "    for t, char in enumerate(sentence):\n",
    "        multiset_abstraction = Counter(sentence[:t+1])\n",
    "        for c in activities:\n",
    "            if c==char: #this will encode present events to the right places\n",
    "                X[i, t+leftpad, act_indices[c]] = 1\n",
    "        X[i, t+leftpad, len(activities)] = t+1\n",
    "        X[i, t+leftpad, len(activities)+1] = sentence_t[t]/divisor\n",
    "        X[i, t+leftpad, len(activities)+2] = sentence_t2[t]/divisor2\n",
    "        X[i, t+leftpad, len(activities)+3] = sentence_t3[t]/86400\n",
    "        X[i, t+leftpad, len(activities)+4] = sentence_t4[t]/7\n",
    "    for c in target_activities:\n",
    "        if c==next_chars[i]:\n",
    "            y_a[i, target_activities_indices[c]] = 1-softness\n",
    "        else:\n",
    "            y_a[i, target_activities_indices[c]] = softness/(len(target_activities)-1)\n",
    "    y_t[i] = next_t/divisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Epoch 1/100\n",
      "44/44 - 43s - loss: 3.4811 - act_output_loss: 2.1214 - time_output_loss: 1.3597 - val_loss: 3.0428 - val_act_output_loss: 1.9265 - val_time_output_loss: 1.1164 - lr: 0.0020 - 43s/epoch - 974ms/step\n",
      "Epoch 2/100\n",
      "44/44 - 39s - loss: 2.7725 - act_output_loss: 1.6469 - time_output_loss: 1.1257 - val_loss: 2.8837 - val_act_output_loss: 1.7658 - val_time_output_loss: 1.1179 - lr: 0.0020 - 39s/epoch - 893ms/step\n",
      "Epoch 3/100\n",
      "44/44 - 35s - loss: 2.5864 - act_output_loss: 1.4963 - time_output_loss: 1.0901 - val_loss: 2.7710 - val_act_output_loss: 1.7175 - val_time_output_loss: 1.0535 - lr: 0.0020 - 35s/epoch - 805ms/step\n",
      "Epoch 4/100\n",
      "44/44 - 37s - loss: 2.4216 - act_output_loss: 1.3498 - time_output_loss: 1.0718 - val_loss: 2.6822 - val_act_output_loss: 1.6190 - val_time_output_loss: 1.0632 - lr: 0.0020 - 37s/epoch - 839ms/step\n",
      "Epoch 5/100\n",
      "44/44 - 43s - loss: 2.2748 - act_output_loss: 1.2116 - time_output_loss: 1.0631 - val_loss: 2.6698 - val_act_output_loss: 1.5921 - val_time_output_loss: 1.0778 - lr: 0.0020 - 43s/epoch - 976ms/step\n",
      "Epoch 6/100\n",
      "44/44 - 44s - loss: 2.1745 - act_output_loss: 1.1231 - time_output_loss: 1.0515 - val_loss: 2.3273 - val_act_output_loss: 1.2994 - val_time_output_loss: 1.0279 - lr: 0.0020 - 44s/epoch - 1s/step\n",
      "Epoch 7/100\n",
      "44/44 - 43s - loss: 2.1045 - act_output_loss: 1.0647 - time_output_loss: 1.0397 - val_loss: 2.1835 - val_act_output_loss: 1.1645 - val_time_output_loss: 1.0190 - lr: 0.0020 - 43s/epoch - 976ms/step\n",
      "Epoch 8/100\n",
      "44/44 - 39s - loss: 2.0278 - act_output_loss: 0.9970 - time_output_loss: 1.0308 - val_loss: 2.0304 - val_act_output_loss: 1.0170 - val_time_output_loss: 1.0134 - lr: 0.0020 - 39s/epoch - 891ms/step\n",
      "Epoch 9/100\n",
      "44/44 - 37s - loss: 1.9889 - act_output_loss: 0.9649 - time_output_loss: 1.0241 - val_loss: 1.9431 - val_act_output_loss: 0.9150 - val_time_output_loss: 1.0281 - lr: 0.0020 - 37s/epoch - 847ms/step\n",
      "Epoch 10/100\n",
      "44/44 - 38s - loss: 1.9504 - act_output_loss: 0.9341 - time_output_loss: 1.0163 - val_loss: 1.8669 - val_act_output_loss: 0.8590 - val_time_output_loss: 1.0079 - lr: 0.0020 - 38s/epoch - 863ms/step\n",
      "Epoch 11/100\n",
      "44/44 - 38s - loss: 1.9189 - act_output_loss: 0.9054 - time_output_loss: 1.0135 - val_loss: 1.8748 - val_act_output_loss: 0.8678 - val_time_output_loss: 1.0070 - lr: 0.0020 - 38s/epoch - 863ms/step\n",
      "Epoch 12/100\n",
      "44/44 - 37s - loss: 1.8650 - act_output_loss: 0.8606 - time_output_loss: 1.0044 - val_loss: 1.7568 - val_act_output_loss: 0.7559 - val_time_output_loss: 1.0009 - lr: 0.0020 - 37s/epoch - 830ms/step\n",
      "Epoch 13/100\n",
      "44/44 - 36s - loss: 1.8484 - act_output_loss: 0.8526 - time_output_loss: 0.9958 - val_loss: 1.7586 - val_act_output_loss: 0.7495 - val_time_output_loss: 1.0091 - lr: 0.0020 - 36s/epoch - 817ms/step\n",
      "Epoch 14/100\n",
      "44/44 - 36s - loss: 1.8339 - act_output_loss: 0.8417 - time_output_loss: 0.9923 - val_loss: 1.7121 - val_act_output_loss: 0.7195 - val_time_output_loss: 0.9927 - lr: 0.0020 - 36s/epoch - 828ms/step\n",
      "Epoch 15/100\n",
      "44/44 - 38s - loss: 1.8102 - act_output_loss: 0.8221 - time_output_loss: 0.9881 - val_loss: 1.6844 - val_act_output_loss: 0.7168 - val_time_output_loss: 0.9676 - lr: 0.0020 - 38s/epoch - 866ms/step\n",
      "Epoch 16/100\n",
      "44/44 - 38s - loss: 1.7746 - act_output_loss: 0.7983 - time_output_loss: 0.9763 - val_loss: 1.6940 - val_act_output_loss: 0.7374 - val_time_output_loss: 0.9566 - lr: 0.0020 - 38s/epoch - 867ms/step\n",
      "Epoch 17/100\n",
      "44/44 - 39s - loss: 1.7560 - act_output_loss: 0.7885 - time_output_loss: 0.9675 - val_loss: 1.6188 - val_act_output_loss: 0.6634 - val_time_output_loss: 0.9554 - lr: 0.0020 - 39s/epoch - 897ms/step\n",
      "Epoch 18/100\n",
      "44/44 - 41s - loss: 1.7105 - act_output_loss: 0.7572 - time_output_loss: 0.9533 - val_loss: 1.5826 - val_act_output_loss: 0.6653 - val_time_output_loss: 0.9173 - lr: 0.0020 - 41s/epoch - 935ms/step\n",
      "Epoch 19/100\n",
      "44/44 - 47s - loss: 1.7151 - act_output_loss: 0.7673 - time_output_loss: 0.9477 - val_loss: 1.5845 - val_act_output_loss: 0.6751 - val_time_output_loss: 0.9094 - lr: 0.0020 - 47s/epoch - 1s/step\n",
      "Epoch 20/100\n",
      "44/44 - 40s - loss: 1.6832 - act_output_loss: 0.7518 - time_output_loss: 0.9313 - val_loss: 1.5621 - val_act_output_loss: 0.6613 - val_time_output_loss: 0.9008 - lr: 0.0020 - 40s/epoch - 920ms/step\n",
      "Epoch 21/100\n",
      "44/44 - 39s - loss: 1.6597 - act_output_loss: 0.7450 - time_output_loss: 0.9146 - val_loss: 1.5547 - val_act_output_loss: 0.6593 - val_time_output_loss: 0.8954 - lr: 0.0020 - 39s/epoch - 876ms/step\n",
      "Epoch 22/100\n",
      "44/44 - 39s - loss: 1.6479 - act_output_loss: 0.7448 - time_output_loss: 0.9030 - val_loss: 1.5562 - val_act_output_loss: 0.6609 - val_time_output_loss: 0.8953 - lr: 0.0020 - 39s/epoch - 876ms/step\n",
      "Epoch 23/100\n",
      "44/44 - 39s - loss: 1.6299 - act_output_loss: 0.7419 - time_output_loss: 0.8881 - val_loss: 1.5081 - val_act_output_loss: 0.6383 - val_time_output_loss: 0.8698 - lr: 0.0020 - 39s/epoch - 888ms/step\n",
      "Epoch 24/100\n",
      "44/44 - 40s - loss: 1.6360 - act_output_loss: 0.7331 - time_output_loss: 0.9029 - val_loss: 1.4955 - val_act_output_loss: 0.6266 - val_time_output_loss: 0.8689 - lr: 0.0020 - 40s/epoch - 899ms/step\n",
      "Epoch 25/100\n",
      "44/44 - 40s - loss: 1.6308 - act_output_loss: 0.7331 - time_output_loss: 0.8978 - val_loss: 1.5154 - val_act_output_loss: 0.6328 - val_time_output_loss: 0.8826 - lr: 0.0020 - 40s/epoch - 900ms/step\n",
      "Epoch 26/100\n",
      "44/44 - 40s - loss: 1.5832 - act_output_loss: 0.7031 - time_output_loss: 0.8800 - val_loss: 1.5162 - val_act_output_loss: 0.6496 - val_time_output_loss: 0.8666 - lr: 0.0020 - 40s/epoch - 918ms/step\n",
      "Epoch 27/100\n",
      "44/44 - 39s - loss: 1.6019 - act_output_loss: 0.7198 - time_output_loss: 0.8821 - val_loss: 1.4932 - val_act_output_loss: 0.6342 - val_time_output_loss: 0.8590 - lr: 0.0020 - 39s/epoch - 888ms/step\n",
      "Epoch 28/100\n",
      "44/44 - 40s - loss: 1.5735 - act_output_loss: 0.6965 - time_output_loss: 0.8770 - val_loss: 1.4698 - val_act_output_loss: 0.6145 - val_time_output_loss: 0.8553 - lr: 0.0020 - 40s/epoch - 904ms/step\n",
      "Epoch 29/100\n",
      "44/44 - 44s - loss: 1.5608 - act_output_loss: 0.6915 - time_output_loss: 0.8693 - val_loss: 1.4604 - val_act_output_loss: 0.6000 - val_time_output_loss: 0.8604 - lr: 0.0020 - 44s/epoch - 999ms/step\n",
      "Epoch 30/100\n",
      "44/44 - 41s - loss: 1.5412 - act_output_loss: 0.6791 - time_output_loss: 0.8622 - val_loss: 1.4645 - val_act_output_loss: 0.6235 - val_time_output_loss: 0.8410 - lr: 0.0020 - 41s/epoch - 934ms/step\n",
      "Epoch 31/100\n",
      "44/44 - 43s - loss: 1.5429 - act_output_loss: 0.6885 - time_output_loss: 0.8544 - val_loss: 1.4693 - val_act_output_loss: 0.6374 - val_time_output_loss: 0.8319 - lr: 0.0020 - 43s/epoch - 976ms/step\n",
      "Epoch 32/100\n",
      "44/44 - 40s - loss: 1.5437 - act_output_loss: 0.6891 - time_output_loss: 0.8546 - val_loss: 1.4438 - val_act_output_loss: 0.6153 - val_time_output_loss: 0.8284 - lr: 0.0020 - 40s/epoch - 918ms/step\n",
      "Epoch 33/100\n",
      "44/44 - 41s - loss: 1.5301 - act_output_loss: 0.6751 - time_output_loss: 0.8549 - val_loss: 1.4503 - val_act_output_loss: 0.6241 - val_time_output_loss: 0.8262 - lr: 0.0020 - 41s/epoch - 935ms/step\n",
      "Epoch 34/100\n",
      "44/44 - 47s - loss: 1.5322 - act_output_loss: 0.6827 - time_output_loss: 0.8495 - val_loss: 1.4835 - val_act_output_loss: 0.6492 - val_time_output_loss: 0.8343 - lr: 0.0020 - 47s/epoch - 1s/step\n",
      "Epoch 35/100\n",
      "44/44 - 44s - loss: 1.5420 - act_output_loss: 0.6814 - time_output_loss: 0.8607 - val_loss: 1.4341 - val_act_output_loss: 0.5994 - val_time_output_loss: 0.8347 - lr: 0.0020 - 44s/epoch - 990ms/step\n",
      "Epoch 36/100\n",
      "44/44 - 42s - loss: 1.5372 - act_output_loss: 0.6769 - time_output_loss: 0.8603 - val_loss: 1.4403 - val_act_output_loss: 0.6068 - val_time_output_loss: 0.8335 - lr: 0.0020 - 42s/epoch - 952ms/step\n",
      "Epoch 37/100\n",
      "44/44 - 39s - loss: 1.4933 - act_output_loss: 0.6486 - time_output_loss: 0.8448 - val_loss: 1.4589 - val_act_output_loss: 0.6220 - val_time_output_loss: 0.8369 - lr: 0.0020 - 39s/epoch - 893ms/step\n",
      "Epoch 38/100\n",
      "44/44 - 41s - loss: 1.5066 - act_output_loss: 0.6615 - time_output_loss: 0.8451 - val_loss: 1.4441 - val_act_output_loss: 0.5957 - val_time_output_loss: 0.8484 - lr: 0.0020 - 41s/epoch - 934ms/step\n",
      "Epoch 39/100\n",
      "44/44 - 39s - loss: 1.5095 - act_output_loss: 0.6642 - time_output_loss: 0.8454 - val_loss: 1.4465 - val_act_output_loss: 0.6048 - val_time_output_loss: 0.8418 - lr: 0.0020 - 39s/epoch - 887ms/step\n",
      "Epoch 40/100\n",
      "44/44 - 39s - loss: 1.5008 - act_output_loss: 0.6525 - time_output_loss: 0.8483 - val_loss: 1.4532 - val_act_output_loss: 0.6007 - val_time_output_loss: 0.8525 - lr: 0.0020 - 39s/epoch - 877ms/step\n",
      "Epoch 41/100\n",
      "44/44 - 39s - loss: 1.4975 - act_output_loss: 0.6489 - time_output_loss: 0.8486 - val_loss: 1.4303 - val_act_output_loss: 0.5870 - val_time_output_loss: 0.8433 - lr: 0.0020 - 39s/epoch - 882ms/step\n",
      "Epoch 42/100\n",
      "44/44 - 39s - loss: 1.4959 - act_output_loss: 0.6520 - time_output_loss: 0.8439 - val_loss: 1.4607 - val_act_output_loss: 0.6226 - val_time_output_loss: 0.8382 - lr: 0.0020 - 39s/epoch - 881ms/step\n",
      "Epoch 43/100\n",
      "44/44 - 39s - loss: 1.4853 - act_output_loss: 0.6495 - time_output_loss: 0.8358 - val_loss: 1.4478 - val_act_output_loss: 0.6144 - val_time_output_loss: 0.8334 - lr: 0.0020 - 39s/epoch - 883ms/step\n",
      "Epoch 44/100\n",
      "44/44 - 39s - loss: 1.4610 - act_output_loss: 0.6366 - time_output_loss: 0.8245 - val_loss: 1.4486 - val_act_output_loss: 0.6051 - val_time_output_loss: 0.8435 - lr: 0.0020 - 39s/epoch - 883ms/step\n",
      "Epoch 45/100\n",
      "44/44 - 39s - loss: 1.4732 - act_output_loss: 0.6383 - time_output_loss: 0.8349 - val_loss: 1.4187 - val_act_output_loss: 0.5917 - val_time_output_loss: 0.8269 - lr: 0.0020 - 39s/epoch - 880ms/step\n",
      "Epoch 46/100\n",
      "44/44 - 39s - loss: 1.4728 - act_output_loss: 0.6291 - time_output_loss: 0.8438 - val_loss: 1.4174 - val_act_output_loss: 0.5931 - val_time_output_loss: 0.8243 - lr: 0.0020 - 39s/epoch - 888ms/step\n",
      "Epoch 47/100\n",
      "44/44 - 42s - loss: 1.4625 - act_output_loss: 0.6374 - time_output_loss: 0.8250 - val_loss: 1.4329 - val_act_output_loss: 0.5940 - val_time_output_loss: 0.8389 - lr: 0.0020 - 42s/epoch - 944ms/step\n",
      "Epoch 48/100\n",
      "44/44 - 43s - loss: 1.4542 - act_output_loss: 0.6266 - time_output_loss: 0.8275 - val_loss: 1.4144 - val_act_output_loss: 0.5944 - val_time_output_loss: 0.8200 - lr: 0.0020 - 43s/epoch - 978ms/step\n",
      "Epoch 49/100\n",
      "44/44 - 43s - loss: 1.4356 - act_output_loss: 0.6200 - time_output_loss: 0.8156 - val_loss: 1.4194 - val_act_output_loss: 0.6059 - val_time_output_loss: 0.8135 - lr: 0.0020 - 43s/epoch - 985ms/step\n",
      "Epoch 50/100\n",
      "44/44 - 43s - loss: 1.4553 - act_output_loss: 0.6313 - time_output_loss: 0.8240 - val_loss: 1.3954 - val_act_output_loss: 0.5841 - val_time_output_loss: 0.8114 - lr: 0.0020 - 43s/epoch - 968ms/step\n",
      "Epoch 51/100\n",
      "44/44 - 43s - loss: 1.4436 - act_output_loss: 0.6218 - time_output_loss: 0.8218 - val_loss: 1.4250 - val_act_output_loss: 0.5972 - val_time_output_loss: 0.8278 - lr: 0.0020 - 43s/epoch - 985ms/step\n",
      "Epoch 52/100\n",
      "44/44 - 39s - loss: 1.4409 - act_output_loss: 0.6247 - time_output_loss: 0.8161 - val_loss: 1.4329 - val_act_output_loss: 0.6142 - val_time_output_loss: 0.8188 - lr: 0.0020 - 39s/epoch - 896ms/step\n",
      "Epoch 53/100\n",
      "44/44 - 39s - loss: 1.4362 - act_output_loss: 0.6082 - time_output_loss: 0.8280 - val_loss: 1.4465 - val_act_output_loss: 0.6149 - val_time_output_loss: 0.8316 - lr: 0.0020 - 39s/epoch - 887ms/step\n",
      "Epoch 54/100\n",
      "44/44 - 41s - loss: 1.4382 - act_output_loss: 0.6095 - time_output_loss: 0.8286 - val_loss: 1.4316 - val_act_output_loss: 0.6017 - val_time_output_loss: 0.8299 - lr: 0.0020 - 41s/epoch - 932ms/step\n",
      "Epoch 55/100\n",
      "44/44 - 40s - loss: 1.4278 - act_output_loss: 0.6195 - time_output_loss: 0.8083 - val_loss: 1.4260 - val_act_output_loss: 0.5909 - val_time_output_loss: 0.8351 - lr: 0.0020 - 40s/epoch - 908ms/step\n",
      "Epoch 56/100\n",
      "44/44 - 39s - loss: 1.4316 - act_output_loss: 0.6134 - time_output_loss: 0.8182 - val_loss: 1.4276 - val_act_output_loss: 0.5987 - val_time_output_loss: 0.8289 - lr: 0.0020 - 39s/epoch - 881ms/step\n",
      "Epoch 57/100\n",
      "44/44 - 41s - loss: 1.4238 - act_output_loss: 0.6008 - time_output_loss: 0.8231 - val_loss: 1.4062 - val_act_output_loss: 0.5844 - val_time_output_loss: 0.8218 - lr: 0.0020 - 41s/epoch - 922ms/step\n",
      "Epoch 58/100\n",
      "44/44 - 39s - loss: 1.4001 - act_output_loss: 0.5851 - time_output_loss: 0.8150 - val_loss: 1.4470 - val_act_output_loss: 0.6097 - val_time_output_loss: 0.8373 - lr: 0.0020 - 39s/epoch - 888ms/step\n",
      "Epoch 59/100\n",
      "44/44 - 39s - loss: 1.4115 - act_output_loss: 0.5908 - time_output_loss: 0.8206 - val_loss: 1.4358 - val_act_output_loss: 0.6083 - val_time_output_loss: 0.8275 - lr: 0.0020 - 39s/epoch - 894ms/step\n",
      "Epoch 60/100\n",
      "44/44 - 39s - loss: 1.4275 - act_output_loss: 0.6112 - time_output_loss: 0.8163 - val_loss: 1.4263 - val_act_output_loss: 0.6130 - val_time_output_loss: 0.8133 - lr: 0.0020 - 39s/epoch - 892ms/step\n",
      "Epoch 61/100\n",
      "44/44 - 40s - loss: 1.3776 - act_output_loss: 0.5745 - time_output_loss: 0.8031 - val_loss: 1.4115 - val_act_output_loss: 0.5825 - val_time_output_loss: 0.8290 - lr: 0.0010 - 40s/epoch - 899ms/step\n",
      "Epoch 62/100\n",
      "44/44 - 41s - loss: 1.3505 - act_output_loss: 0.5675 - time_output_loss: 0.7830 - val_loss: 1.4018 - val_act_output_loss: 0.5912 - val_time_output_loss: 0.8105 - lr: 0.0010 - 41s/epoch - 923ms/step\n",
      "Epoch 63/100\n",
      "44/44 - 40s - loss: 1.3710 - act_output_loss: 0.5675 - time_output_loss: 0.8035 - val_loss: 1.3823 - val_act_output_loss: 0.5803 - val_time_output_loss: 0.8020 - lr: 0.0010 - 40s/epoch - 902ms/step\n",
      "Epoch 64/100\n",
      "44/44 - 41s - loss: 1.3599 - act_output_loss: 0.5562 - time_output_loss: 0.8037 - val_loss: 1.3879 - val_act_output_loss: 0.5811 - val_time_output_loss: 0.8067 - lr: 0.0010 - 41s/epoch - 938ms/step\n",
      "Epoch 65/100\n",
      "44/44 - 40s - loss: 1.3512 - act_output_loss: 0.5509 - time_output_loss: 0.8003 - val_loss: 1.3938 - val_act_output_loss: 0.5958 - val_time_output_loss: 0.7981 - lr: 0.0010 - 40s/epoch - 912ms/step\n",
      "Epoch 66/100\n",
      "44/44 - 40s - loss: 1.3665 - act_output_loss: 0.5740 - time_output_loss: 0.7924 - val_loss: 1.3885 - val_act_output_loss: 0.5792 - val_time_output_loss: 0.8093 - lr: 0.0010 - 40s/epoch - 916ms/step\n",
      "Epoch 67/100\n",
      "44/44 - 40s - loss: 1.3622 - act_output_loss: 0.5567 - time_output_loss: 0.8054 - val_loss: 1.3971 - val_act_output_loss: 0.5950 - val_time_output_loss: 0.8021 - lr: 0.0010 - 40s/epoch - 913ms/step\n",
      "Epoch 68/100\n",
      "44/44 - 41s - loss: 1.3676 - act_output_loss: 0.5639 - time_output_loss: 0.8037 - val_loss: 1.4041 - val_act_output_loss: 0.6073 - val_time_output_loss: 0.7968 - lr: 0.0010 - 41s/epoch - 924ms/step\n",
      "Epoch 69/100\n",
      "44/44 - 40s - loss: 1.3564 - act_output_loss: 0.5489 - time_output_loss: 0.8074 - val_loss: 1.4090 - val_act_output_loss: 0.5977 - val_time_output_loss: 0.8113 - lr: 0.0010 - 40s/epoch - 909ms/step\n",
      "Epoch 70/100\n",
      "44/44 - 40s - loss: 1.3494 - act_output_loss: 0.5554 - time_output_loss: 0.7940 - val_loss: 1.3852 - val_act_output_loss: 0.5834 - val_time_output_loss: 0.8019 - lr: 0.0010 - 40s/epoch - 907ms/step\n",
      "Epoch 71/100\n",
      "44/44 - 39s - loss: 1.3454 - act_output_loss: 0.5475 - time_output_loss: 0.7980 - val_loss: 1.4214 - val_act_output_loss: 0.5929 - val_time_output_loss: 0.8285 - lr: 0.0010 - 39s/epoch - 879ms/step\n",
      "Epoch 72/100\n",
      "44/44 - 39s - loss: 1.3443 - act_output_loss: 0.5502 - time_output_loss: 0.7941 - val_loss: 1.4090 - val_act_output_loss: 0.5992 - val_time_output_loss: 0.8098 - lr: 0.0010 - 39s/epoch - 881ms/step\n",
      "Epoch 73/100\n",
      "44/44 - 40s - loss: 1.3249 - act_output_loss: 0.5381 - time_output_loss: 0.7868 - val_loss: 1.4214 - val_act_output_loss: 0.6112 - val_time_output_loss: 0.8102 - lr: 0.0010 - 40s/epoch - 914ms/step\n",
      "Epoch 74/100\n",
      "44/44 - 40s - loss: 1.3269 - act_output_loss: 0.5397 - time_output_loss: 0.7872 - val_loss: 1.3931 - val_act_output_loss: 0.5920 - val_time_output_loss: 0.8011 - lr: 5.0000e-04 - 40s/epoch - 917ms/step\n",
      "Epoch 75/100\n",
      "44/44 - 41s - loss: 1.3055 - act_output_loss: 0.5233 - time_output_loss: 0.7822 - val_loss: 1.4048 - val_act_output_loss: 0.5929 - val_time_output_loss: 0.8119 - lr: 5.0000e-04 - 41s/epoch - 938ms/step\n",
      "Epoch 76/100\n",
      "44/44 - 39s - loss: 1.3139 - act_output_loss: 0.5186 - time_output_loss: 0.7953 - val_loss: 1.3825 - val_act_output_loss: 0.5828 - val_time_output_loss: 0.7997 - lr: 5.0000e-04 - 39s/epoch - 892ms/step\n",
      "Epoch 77/100\n",
      "44/44 - 40s - loss: 1.3171 - act_output_loss: 0.5279 - time_output_loss: 0.7893 - val_loss: 1.3879 - val_act_output_loss: 0.5907 - val_time_output_loss: 0.7972 - lr: 5.0000e-04 - 40s/epoch - 916ms/step\n",
      "Epoch 78/100\n",
      "44/44 - 40s - loss: 1.3051 - act_output_loss: 0.5193 - time_output_loss: 0.7858 - val_loss: 1.3880 - val_act_output_loss: 0.5870 - val_time_output_loss: 0.8010 - lr: 5.0000e-04 - 40s/epoch - 907ms/step\n",
      "Epoch 79/100\n",
      "44/44 - 40s - loss: 1.3209 - act_output_loss: 0.5250 - time_output_loss: 0.7959 - val_loss: 1.3857 - val_act_output_loss: 0.5877 - val_time_output_loss: 0.7979 - lr: 5.0000e-04 - 40s/epoch - 907ms/step\n",
      "Epoch 80/100\n",
      "44/44 - 40s - loss: 1.3248 - act_output_loss: 0.5328 - time_output_loss: 0.7921 - val_loss: 1.3854 - val_act_output_loss: 0.5886 - val_time_output_loss: 0.7968 - lr: 5.0000e-04 - 40s/epoch - 910ms/step\n",
      "Epoch 81/100\n",
      "44/44 - 39s - loss: 1.2970 - act_output_loss: 0.5182 - time_output_loss: 0.7788 - val_loss: 1.3989 - val_act_output_loss: 0.5983 - val_time_output_loss: 0.8006 - lr: 5.0000e-04 - 39s/epoch - 892ms/step\n",
      "Epoch 82/100\n",
      "44/44 - 38s - loss: 1.2965 - act_output_loss: 0.5170 - time_output_loss: 0.7794 - val_loss: 1.3992 - val_act_output_loss: 0.5931 - val_time_output_loss: 0.8061 - lr: 5.0000e-04 - 38s/epoch - 875ms/step\n",
      "Epoch 83/100\n",
      "44/44 - 39s - loss: 1.2978 - act_output_loss: 0.5262 - time_output_loss: 0.7715 - val_loss: 1.3905 - val_act_output_loss: 0.6004 - val_time_output_loss: 0.7901 - lr: 5.0000e-04 - 39s/epoch - 876ms/step\n",
      "Epoch 84/100\n",
      "44/44 - 39s - loss: 1.2746 - act_output_loss: 0.5116 - time_output_loss: 0.7630 - val_loss: 1.3815 - val_act_output_loss: 0.5906 - val_time_output_loss: 0.7909 - lr: 2.5000e-04 - 39s/epoch - 882ms/step\n",
      "Epoch 85/100\n",
      "44/44 - 40s - loss: 1.2907 - act_output_loss: 0.5138 - time_output_loss: 0.7770 - val_loss: 1.3888 - val_act_output_loss: 0.5945 - val_time_output_loss: 0.7943 - lr: 2.5000e-04 - 40s/epoch - 901ms/step\n",
      "Epoch 86/100\n",
      "44/44 - 39s - loss: 1.2783 - act_output_loss: 0.5162 - time_output_loss: 0.7622 - val_loss: 1.3852 - val_act_output_loss: 0.5909 - val_time_output_loss: 0.7943 - lr: 2.5000e-04 - 39s/epoch - 892ms/step\n",
      "Epoch 87/100\n",
      "44/44 - 39s - loss: 1.2679 - act_output_loss: 0.5049 - time_output_loss: 0.7631 - val_loss: 1.3885 - val_act_output_loss: 0.5908 - val_time_output_loss: 0.7976 - lr: 2.5000e-04 - 39s/epoch - 875ms/step\n",
      "Epoch 88/100\n",
      "44/44 - 38s - loss: 1.2603 - act_output_loss: 0.4923 - time_output_loss: 0.7680 - val_loss: 1.3853 - val_act_output_loss: 0.5922 - val_time_output_loss: 0.7930 - lr: 2.5000e-04 - 38s/epoch - 867ms/step\n",
      "Epoch 89/100\n",
      "44/44 - 38s - loss: 1.2687 - act_output_loss: 0.5025 - time_output_loss: 0.7662 - val_loss: 1.3776 - val_act_output_loss: 0.5863 - val_time_output_loss: 0.7913 - lr: 2.5000e-04 - 38s/epoch - 864ms/step\n",
      "Epoch 90/100\n",
      "44/44 - 40s - loss: 1.2896 - act_output_loss: 0.5152 - time_output_loss: 0.7744 - val_loss: 1.3840 - val_act_output_loss: 0.5888 - val_time_output_loss: 0.7953 - lr: 2.5000e-04 - 40s/epoch - 915ms/step\n",
      "Epoch 91/100\n",
      "44/44 - 41s - loss: 1.2929 - act_output_loss: 0.5017 - time_output_loss: 0.7912 - val_loss: 1.3813 - val_act_output_loss: 0.5907 - val_time_output_loss: 0.7906 - lr: 2.5000e-04 - 41s/epoch - 922ms/step\n",
      "Epoch 92/100\n",
      "44/44 - 41s - loss: 1.2847 - act_output_loss: 0.5014 - time_output_loss: 0.7833 - val_loss: 1.3845 - val_act_output_loss: 0.5939 - val_time_output_loss: 0.7906 - lr: 2.5000e-04 - 41s/epoch - 940ms/step\n",
      "Epoch 93/100\n",
      "44/44 - 40s - loss: 1.2945 - act_output_loss: 0.5028 - time_output_loss: 0.7917 - val_loss: 1.3898 - val_act_output_loss: 0.5967 - val_time_output_loss: 0.7931 - lr: 2.5000e-04 - 40s/epoch - 912ms/step\n",
      "Epoch 94/100\n",
      "44/44 - 40s - loss: 1.2731 - act_output_loss: 0.5015 - time_output_loss: 0.7715 - val_loss: 1.3897 - val_act_output_loss: 0.5921 - val_time_output_loss: 0.7976 - lr: 2.5000e-04 - 40s/epoch - 898ms/step\n",
      "Epoch 95/100\n",
      "44/44 - 40s - loss: 1.2801 - act_output_loss: 0.5030 - time_output_loss: 0.7771 - val_loss: 1.3836 - val_act_output_loss: 0.5949 - val_time_output_loss: 0.7887 - lr: 2.5000e-04 - 40s/epoch - 898ms/step\n",
      "Epoch 96/100\n",
      "44/44 - 39s - loss: 1.2889 - act_output_loss: 0.5157 - time_output_loss: 0.7732 - val_loss: 1.3864 - val_act_output_loss: 0.5969 - val_time_output_loss: 0.7894 - lr: 2.5000e-04 - 39s/epoch - 883ms/step\n",
      "Epoch 97/100\n",
      "44/44 - 41s - loss: 1.2668 - act_output_loss: 0.4952 - time_output_loss: 0.7716 - val_loss: 1.3765 - val_act_output_loss: 0.5907 - val_time_output_loss: 0.7857 - lr: 2.5000e-04 - 41s/epoch - 924ms/step\n",
      "Epoch 98/100\n",
      "44/44 - 40s - loss: 1.2767 - act_output_loss: 0.5000 - time_output_loss: 0.7767 - val_loss: 1.3816 - val_act_output_loss: 0.5968 - val_time_output_loss: 0.7848 - lr: 2.5000e-04 - 40s/epoch - 902ms/step\n",
      "Epoch 99/100\n",
      "44/44 - 40s - loss: 1.2754 - act_output_loss: 0.5103 - time_output_loss: 0.7651 - val_loss: 1.3857 - val_act_output_loss: 0.6003 - val_time_output_loss: 0.7854 - lr: 2.5000e-04 - 40s/epoch - 911ms/step\n",
      "Epoch 100/100\n",
      "44/44 - 40s - loss: 1.2773 - act_output_loss: 0.5110 - time_output_loss: 0.7663 - val_loss: 1.3840 - val_act_output_loss: 0.5984 - val_time_output_loss: 0.7857 - lr: 2.5000e-04 - 40s/epoch - 916ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x192451d1010>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model: \n",
    "print('Build model...')\n",
    "main_input = Input(shape=(maxlen, num_features), name='main_input')\n",
    "# train a 2-layer LSTM with one shared layer\n",
    "l1 = LSTM(100, implementation=2, kernel_initializer='glorot_uniform', return_sequences=True, dropout=0.2)(main_input) # the shared layer\n",
    "b1 = BatchNormalization()(l1)\n",
    "l2_1 = LSTM(100, implementation=2, kernel_initializer='glorot_uniform', return_sequences=False, dropout=0.2)(b1) # the layer specialized in activity prediction\n",
    "b2_1 = BatchNormalization()(l2_1)\n",
    "l2_2 = LSTM(100, implementation=2, kernel_initializer='glorot_uniform', return_sequences=False, dropout=0.2)(b1) # the layer specialized in time prediction\n",
    "b2_2 = BatchNormalization()(l2_2)\n",
    "act_output = Dense(len(target_activities), activation='softmax', kernel_initializer='glorot_uniform', name='act_output')(b2_1)\n",
    "time_output = Dense(1, kernel_initializer='glorot_uniform', name='time_output')(b2_2)\n",
    "\n",
    "model = Model(inputs=[main_input], outputs=[act_output, time_output])\n",
    "\n",
    "opt = Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, clipvalue=3)\n",
    "\n",
    "model.compile(loss={'act_output':'categorical_crossentropy', 'time_output':'mae'}, optimizer=opt)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=42)\n",
    "model_checkpoint = ModelCheckpoint('output_files/models/model_{epoch:02d}-{val_loss:.2f}.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "model.fit(X, {'act_output':y_a, 'time_output':y_t}, validation_split=0.2, verbose=2, callbacks=[early_stopping, model_checkpoint, lr_reducer], batch_size=maxlen, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " main_input (InputLayer)     [(None, 119, 20)]            0         []                            \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)               (None, 119, 100)             48400     ['main_input[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 119, 100)             400       ['lstm_6[0][0]']              \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)               (None, 100)                  80400     ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " lstm_8 (LSTM)               (None, 100)                  80400     ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 100)                  400       ['lstm_7[0][0]']              \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 100)                  400       ['lstm_8[0][0]']              \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " act_output (Dense)          (None, 15)                   1515      ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " time_output (Dense)         (None, 1)                    101       ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 212016 (828.19 KB)\n",
      "Trainable params: 211416 (825.84 KB)\n",
      "Non-trainable params: 600 (2.34 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pump Circulation Flow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of activities', df['concept:name'].nunique())\n",
    "df['concept:name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['batch_id'] = df.index.get_level_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('there are',df['batch_id'].nunique(), 'case IDs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Manifold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
